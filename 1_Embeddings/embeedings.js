import 'dotenv/config'
import {OpenAI} from 'openai';
const client=new OpenAI()

async function init(){
    const embedding= await client.embeddings.create({
    model:"text-embedding-3-small",
    input:"Started learning vector embedding",
    encoding_format:"float",
})
    console.log(embedding.data);/*
    Outpur is
[
  {
    object: 'embedding',
    index: 0,
    embedding: [
       -0.016916797, -0.012022548, -0.00010482199,  -0.045326684,
       -0.029003913,  0.010472918,    0.033162087,   0.027428456,
       -0.027944999,  0.060848814,    0.026989393,  0.0013075005,
       -0.023476899, -0.047263723,    0.021849787,   0.005920879,
       -0.010343782,  0.016296946,   -0.010414806,   0.027041048,
        0.020790873, -0.037940115,    0.026434109,   0.035202432,
        0.026808603, -0.030450234,     0.06374146,    0.04491345,
        0.018828006, -0.054340366,   -0.022159712,  -0.035460707,
       -0.016477736, -0.008484226,   -0.031974036, -0.0033187915,
       0.0012929727,  0.017962797,   -0.053617205,    0.02031307,
        0.025310628,  0.001230019,     0.01866013,   0.015367166,
       0.0026424425, 0.0007643228,   -0.024393763,  0.0045810943,
       -0.025698034,   0.01455361,   -0.046695523,  -0.022405071,
        -0.05697474,  0.006347027,  -0.0032865074,   0.016529389,
       -0.021772305, -0.044681005,   -0.023864307,   0.005384965,
        0.049949747,  0.008781238,     0.01689097,    -0.0368812,
        0.025220232,  0.014850623,   -0.059299182,  -0.008413201,
       -0.009116991, -0.017330032,    0.008981398,  -0.008994312,
        0.012726339, -0.019008797,    0.007825633,   0.016464822,
       -0.050905354,  0.039696362,    0.014243685,   0.008154929,
      -0.0042388844,  0.012545548,   0.0061952923,  -0.037346087,
       -0.050827872,  -0.06079716,    0.014295339,  0.0037772236,
        0.003347847,  -0.03228396,   -0.020364724,  -0.020700477,
       -0.032361444,  -0.03057937,     0.05997069,   0.049149107,
       -0.006469706, -0.029597938,  -0.0029184702,  -0.017265463,
      ... 1436 more items
    ]
  }
] 
These values are nothing but the points where the words/tokens will be in the graph of all things


text-embedding small uses embedding lenth 1536
text-embedding large uses embedding lenth 3072

*/

}
init();